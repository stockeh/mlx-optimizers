<p align="center">
  <img src="https://github.com/user-attachments/assets/f197f80d-8b9c-470b-b12f-85406f9eddea#gh-dark-mode-only" alt="logo">
</p>
<p align="center">
  <img src="https://github.com/user-attachments/assets/9b754e8e-3d4b-47c9-903f-612fa2dc2a71#gh-light-mode-only" alt="logo">
</p>

# 

A library to experiment with new optimizers in [MLX](https://github.com/ml-explore/mlx).

```python
import mlx_optimizers as optim

#... model, grads, etc.
optimizer = optim.DiffGrad(learning_rate=0.001)
optimizer.update(model, grads)
```

Coming to pip soon! :tada: 
